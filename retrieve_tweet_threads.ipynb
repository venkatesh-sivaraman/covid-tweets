{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Thread Augmentation\n",
    "\n",
    "Many tweets are part of **threads**, which consist of multiple tweets in a linked-list sequence of replies to one another. Since some of the tweets may not have contained the original coronavirus keywords, this step pulls tweets in threads for which at least one tweet is in the dataset. This consists of three steps:\n",
    "\n",
    "1. Extract **upstream tweets**, which are explicitly linked to in the `in_reply_to_status_id_str` field of the tweet. We can do this using a simple hydrate command with Twarc.\n",
    "2. Extract **downstream tweets**, which are not explicitly linked. Instead, we look for tweets in each user's timeline within a two-day window on either side of their tweets in the dataset, and recursively find the tweets that link back to the original dataset.\n",
    "3. Join these two sets together with the original tweet dataset, and assign each tweet a **thread ID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6608,
     "status": "ok",
     "timestamp": 1591758108595,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "SQUjbWGCL1eD",
    "outputId": "bd149b48-5409-429f-e3ca-e68dd4717452"
   },
   "outputs": [],
   "source": [
    "import twarc\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n",
    "\n",
    "Input the paths to your Twarc credentials, and input and output paths below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Twarc credentials path (usually expanded version of ~/.twarc)\n",
    "credentials_path = \"/Users/venkatesh-sivaraman/.twarc\"\n",
    "\n",
    "# Path to CSV file batches\n",
    "input_dir = \"raw_data\"\n",
    "\n",
    "# Path to scratch directory for intermediate results\n",
    "intermediate_dir = \"intermediate_data\"\n",
    "if not os.path.exists(intermediate_dir):\n",
    "    os.mkdir(intermediate_dir)\n",
    "    \n",
    "# Path to output directory\n",
    "output_dir = \"intermediate_data\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19522,
     "status": "ok",
     "timestamp": 1591663290062,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "kMXLYCPy3fS-",
    "outputId": "c5398ac5-cc38-442e-8756-895c5a4b212d"
   },
   "outputs": [],
   "source": [
    "# Load input tweets\n",
    "filenames = [os.path.join(input_dir, path) for path in os.listdir(input_dir)\n",
    "                 if path.endswith(\".csv\") and not path.startswith(\".\")]\n",
    "df = pd.concat([pd.read_csv(filename, dtype=utils.dtype_spec, lineterminator='\\n')\n",
    "                for filename in filenames])\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')].reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58KpiRbtZUUW"
   },
   "outputs": [],
   "source": [
    "# Load Twarc object\n",
    "t = utils.load_twarc(credentials_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MchFjBBGvTcL"
   },
   "source": [
    "# Upstream Tweets\n",
    "\n",
    "We want to extract specifically all messages that were replied to by a tweet in the dataset, or that reply to a tweet in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1591663399329,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "jyXWcY2lwpb3",
    "outputId": "3a2b277b-dd0a-4dcc-b2c3-a423db2687b1"
   },
   "outputs": [],
   "source": [
    "reply_ids = df[~pd.isna(df.reply_to_id) & (df.reply_to_user == df.user_id)].reply_to_id.unique().tolist()\n",
    "print(\"{} reply IDs\".format(len(reply_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 437126,
     "status": "ok",
     "timestamp": 1591663893108,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "qTwEBgrfwbfI",
    "outputId": "03aac3e9-e575-4f85-e797-83eefde79226",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recursively extract replies\n",
    "seen_ids = set()\n",
    "reply_ids = list(set(reply_ids))\n",
    "hydrated_replies = []\n",
    "i = 0\n",
    "\n",
    "while reply_ids:\n",
    "    print(\"Round {}, {} tweets to hydrate\".format(i, len(reply_ids)))\n",
    "    new_replies = list(t.hydrate(reply_ids))\n",
    "    hydrated_replies += new_replies\n",
    "    seen_ids |= set([tweet[\"id_str\"] for tweet in new_replies])\n",
    "    # Mark tweets that are in reply to a message by the same user for the next round\n",
    "    reply_ids = [tweet[\"in_reply_to_status_id_str\"] for tweet in new_replies\n",
    "                 if tweet[\"in_reply_to_status_id_str\"] is not None and\n",
    "                 tweet[\"in_reply_to_status_id_str\"] not in seen_ids and\n",
    "                 tweet[\"in_reply_to_user_id_str\"] == tweet[\"user\"][\"id_str\"]]\n",
    "    i += 1\n",
    "\n",
    "# Write upstream tweets as JSON\n",
    "print(\"Writing JSON...\")\n",
    "upstream_tweets = []\n",
    "with open(os.path.join(intermediate_dir, \"all_upstream_tweets.json\"), \"w\") as file:\n",
    "    for item in hydrated_replies:\n",
    "        tweet = json.dumps(item)\n",
    "        file.write(tweet + \"\\n\")\n",
    "        upstream_tweets.append(utils.json_to_tweet(item))\n",
    "\n",
    "print(\"Writing CSV...\")\n",
    "upstream_df = pd.DataFrame(upstream_tweets)\n",
    "upstream_df.to_csv(os.path.join(intermediate_dir, \"all_upstream_tweets.csv\"),\n",
    "                   line_terminator='\\n')\n",
    "print(\"Wrote {} upstream tweets.\".format(len(hydrated_replies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v75HK3IWx5gk"
   },
   "source": [
    "# Downstream Tweets\n",
    "\n",
    "Next use user timelines to find tweets that reply to tweets in the dataset. To do this efficiently, we find a unique set of users and find a consensus date window in which to search for tweets. We assume that replies occur within two days of the original tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 192329,
     "status": "ok",
     "timestamp": 1591664198158,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "pMBNe7zrxgQl",
    "outputId": "7f5138cf-154e-4eca-d8e9-260a0b1dd433"
   },
   "outputs": [],
   "source": [
    "# First establish a list of reference IDs for each date\n",
    "def get_date(tweet, day_delta=0):\n",
    "    date = datetime.datetime.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y')\n",
    "    if day_delta != 0:\n",
    "        date = date + datetime.timedelta(days=day_delta)\n",
    "    return datetime.date.strftime(date, '%Y-%m-%d')\n",
    "\n",
    "min_ids = {}\n",
    "max_ids = {}\n",
    "for i, tweet in df.iterrows():\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "    id_num = int(tweet[\"id\"])\n",
    "    date = get_date(tweet)\n",
    "    min_ids[date] = min(min_ids.get(date, 1e30), id_num)\n",
    "    max_ids[date] = max(max_ids.get(date, 0), id_num)\n",
    "\n",
    "print(sorted(min_ids.items())[-5:], sorted(max_ids.items())[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8851,
     "status": "ok",
     "timestamp": 1591664284691,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "a1fz2GFpzj9P",
    "outputId": "7df70d08-302e-4f87-bcaa-5c8a0a8cece2"
   },
   "outputs": [],
   "source": [
    "# Now get a set of users and the required search dates\n",
    "user_dates = {}\n",
    "\n",
    "tweets_with_replies = df[~pd.isna(df.reply_to_id) & (df.reply_to_user == df.user_id)]\n",
    "for i, tweet in tweets_with_replies.iterrows():\n",
    "    user = tweet[\"user_id\"]\n",
    "    min_date = get_date(tweet, -2)\n",
    "    max_date = get_date(tweet, 2)\n",
    "    if user in user_dates:\n",
    "        user_dates[user] = (min(min_date, user_dates[user][0]),\n",
    "                          min(max_date, user_dates[user][1]))\n",
    "    else:\n",
    "        user_dates[user] = (min_date, max_date)\n",
    "\n",
    "print(\"{} users\".format(len(user_dates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1591664288668,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "ehqJ3gHc2CSe",
    "outputId": "1750197e-f420-4b33-f4c5-4c14a415b0e4"
   },
   "outputs": [],
   "source": [
    "# Fill in reference IDs for dates that aren't in the set. To do this, we'll create two\n",
    "# rough, conservative linear models for tweet IDs over time by estimating the increment\n",
    "# in the minimum and maximum tweet IDs per day.\n",
    "\n",
    "# Note that we're going to give each tweet a two-day interval on either side, so the\n",
    "# exactness of this estimate isn't important except to improve the performance of the\n",
    "# tweet scraper.\n",
    "\n",
    "available_days = sorted(min_ids.keys())\n",
    "series = [available_days[0]]\n",
    "current = series[-1]\n",
    "\n",
    "min_id_items = []\n",
    "max_id_items = []\n",
    "\n",
    "date_index = 0\n",
    "while current != available_days[-1]:\n",
    "    date = datetime.datetime.strptime(current, '%Y-%m-%d')\n",
    "    current = datetime.date.strftime(date + datetime.timedelta(days=1), '%Y-%m-%d')\n",
    "    if current in min_ids:\n",
    "        min_id_items.append((date_index, min_ids[current]))\n",
    "    if current in max_ids:\n",
    "        max_id_items.append((date_index, max_ids[current]))\n",
    "    series.append(current)\n",
    "    date_index += 1\n",
    "\n",
    "min_inc_per_day = (min_id_items[-1][1] - min_id_items[0][1]) / (min_id_items[-1][0] - min_id_items[0][0])\n",
    "max_inc_per_day = (max_id_items[-1][1] - max_id_items[0][1]) / (max_id_items[-1][0] - max_id_items[0][0])\n",
    "earliest_date = datetime.datetime.strptime(available_days[0], '%Y-%m-%d')\n",
    "\n",
    "def get_min_id(date_str):\n",
    "    \"\"\"Estimates the minimum tweet ID for the given date string, in the format YYYY-MM-DD.\"\"\"\n",
    "    date = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    days = (date - earliest_date).days\n",
    "    return min_ids[available_days[0]] + days * min_inc_per_day\n",
    "\n",
    "def get_max_id(date_str):\n",
    "    \"\"\"Estimates the maximum tweet ID for the given date string, in the format YYYY-MM-DD.\"\"\"\n",
    "    date = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    days = (date - earliest_date).days\n",
    "    return max_ids[available_days[0]] + days * max_inc_per_day\n",
    "\n",
    "print(\"Estimate:\", get_min_id(\"2020-02-04\"), \"Actual:\", min_ids[\"2020-02-04\"])\n",
    "print(\"Estimate:\", get_max_id(\"2020-02-08\"), \"Actual:\", max_ids[\"2020-02-08\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15032098,
     "status": "ok",
     "timestamp": 1591679441863,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "qObjCq4u1a3Z",
    "outputId": "35b56c6e-0f72-4005-85a8-588ea0c2f80a"
   },
   "outputs": [],
   "source": [
    "current_batch = []\n",
    "current_csv = []\n",
    "batch_idx = 0\n",
    "\n",
    "user_items = sorted(user_dates.items())\n",
    "\n",
    "i = 0\n",
    "for i, (user_id, (min_date, max_date)) in enumerate(user_items):\n",
    "    if i % 100 == 0:\n",
    "        # Periodically sleep to appease the Twitter rate limiting gods\n",
    "        print(i)\n",
    "        time.sleep(20)\n",
    "    i += 1\n",
    "    \n",
    "    # Compute the boundary tweet IDs needed to search the Twitter timeline for this user\n",
    "    min_id = int(get_min_id(min_date))\n",
    "    max_id = int(get_max_id(max_date))\n",
    "    for tweet in t.timeline(user_id=user_id, max_id=max_id, since_id=min_id):\n",
    "        current_batch.append(tweet)\n",
    "        current_csv.append(utils.json_to_tweet(tweet))\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Writing\")\n",
    "        with open(os.path.join(intermediate_dir, \"timeline_tweets_{}.json\".format(batch_idx)), \"w\") as file:\n",
    "            for item in current_batch:\n",
    "                file.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "        batch_df = pd.DataFrame(current_csv)\n",
    "        batch_df.to_csv(os.path.join(intermediate_dir, \"timeline_tweets_{}.csv\".format(batch_idx)),\n",
    "                      line_terminator=\"\\n\")\n",
    "        batch_idx += 1\n",
    "        current_batch = []\n",
    "        current_csv = []\n",
    "        \n",
    "# Write out the stragglers\n",
    "print(\"Writing last batch\")\n",
    "with open(os.path.join(intermediate_dir, \"timeline_tweets_{}.json\".format(batch_idx)), \"w\") as file:\n",
    "    for item in current_batch:\n",
    "        file.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "batch_df = pd.DataFrame(current_csv)\n",
    "batch_df.to_csv(os.path.join(intermediate_dir, \"timeline_tweets_{}.csv\".format(batch_idx)), line_terminator='\\n')\n",
    "batch_idx += 1\n",
    "current_batch = []\n",
    "current_csv = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_THMO6qdStE"
   },
   "source": [
    "# Filter Downstream Tweets for Threads\n",
    "\n",
    "The above timeline tweets include all tweets by the specified users - find only the tweets that are part of threads in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4493,
     "status": "ok",
     "timestamp": 1591712021100,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "EQKKdyd4Rdx2",
    "outputId": "97a41964-bfa4-4071-9132-cbe60a4498a0"
   },
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "path = os.path.join(intermediate_dir, \"timeline_tweets_{}.csv\".format(batch_idx))\n",
    "timelines = None\n",
    "while os.path.exists(path):\n",
    "    print(\"Reading {}...\".format(os.path.basename(path)))\n",
    "    sub_df = pd.read_csv(path, dtype=utils.dtype_spec, lineterminator='\\n')\n",
    "    if timelines is None:\n",
    "        timelines = sub_df\n",
    "    else:\n",
    "        timelines = pd.concat([timelines, sub_df])\n",
    "    batch_idx += 1\n",
    "    path = os.path.join(intermediate_dir, \"timeline_tweets_{}.csv\".format(batch_idx))\n",
    "timelines = timelines.loc[:, ~timelines.columns.str.contains('^Unnamed')].reset_index(drop=True)    \n",
    "\n",
    "timelines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1591712029313,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "MzI3Q_gDRzev",
    "outputId": "ab6f256a-2328-4ee5-949b-eb8cd10eb3c1"
   },
   "outputs": [],
   "source": [
    "# Get the set of IDs that are allowed reply to from the original dataframe\n",
    "possible_reply_parents = set(df.id.tolist())\n",
    "print(\"{} possible reply parents\".format(len(possible_reply_parents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1848980,
     "status": "ok",
     "timestamp": 1591714459873,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "lHwpVY7XSCy1",
    "outputId": "137a7d3d-1229-4d2d-cff6-d342140ad885"
   },
   "outputs": [],
   "source": [
    "# Recursively find downstream tweets\n",
    "ids_to_check = possible_reply_parents\n",
    "replies = []\n",
    "round_num = 0\n",
    "while ids_to_check:\n",
    "    new_ids = set()\n",
    "    for i, row in timelines[~pd.isna(timelines.reply_to_id)].iterrows():\n",
    "        if (row[\"reply_to_id\"] in ids_to_check and \n",
    "            row[\"reply_to_user\"] == row[\"user_id\"]):\n",
    "            replies.append(row)\n",
    "            new_ids.add(row[\"id\"])\n",
    "    print(\"Round {}: {} replies added\".format(round_num, len(new_ids)))\n",
    "    ids_to_check = new_ids\n",
    "    round_num += 1\n",
    "\n",
    "replies_df = pd.DataFrame(replies)\n",
    "replies_df.to_csv(os.path.join(intermediate_dir, \"threaded_downstream_tweets.csv\"), line_terminator='\\n')\n",
    "print(\"Found {} downstream tweets that are linked to a tweet in the original dataset.\".format(len(replies_df)))\n",
    "\n",
    "replies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vG2NsA_EdguL"
   },
   "source": [
    "# Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32586,
     "status": "ok",
     "timestamp": 1591714819784,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "-3n1bE2FKmSJ",
    "outputId": "5a5d298b-896b-42dc-ad02-9e063785e615"
   },
   "outputs": [],
   "source": [
    "# Let's build a set of all the threaded tweets we know about.\n",
    "all_threaded_tweets = pd.concat([\n",
    "  pd.read_csv(os.path.join(intermediate_dir, \"threaded_downstream_tweets.csv\"), dtype=utils.dtype_spec, index_col=0, lineterminator='\\n'),\n",
    "  pd.read_csv(os.path.join(intermediate_dir, \"all_upstream_tweets.csv\"), dtype=utils.dtype_spec, index_col=0, lineterminator='\\n'),\n",
    "  df,\n",
    "])\n",
    "\n",
    "print(\"{} tweets total\".format(len(all_threaded_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262868,
     "status": "ok",
     "timestamp": 1591715163345,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "xapZie5qK7Uq",
    "outputId": "6ac45b30-83da-46aa-e61e-bfef4f38ba92"
   },
   "outputs": [],
   "source": [
    "# Build a dataframe of threads\n",
    "threads_data = []\n",
    "index_mapping = {}\n",
    "print(\"Sorting...\")\n",
    "dedup_tweets = all_threaded_tweets.drop_duplicates(\"id\")\n",
    "dedup_tweets[\"id_num\"] = dedup_tweets[\"id\"].astype(int)\n",
    "dedup_tweets = dedup_tweets.sort_values(\"id_num\", ascending=False).reset_index()\n",
    "print(\"Done sorting\")\n",
    "\n",
    "couldnt_find = 0\n",
    "found = 0\n",
    "for i, row in dedup_tweets.iterrows():\n",
    "    if i % 10000 == 0: print(i, couldnt_find, found)\n",
    "\n",
    "    if row[\"id\"] in index_mapping:\n",
    "        found += 1\n",
    "        # Place the row's tweet text into the appropriate thread\n",
    "        threads_data[index_mapping[row[\"id\"]]].insert(0, row)\n",
    "        if not pd.isna(row.reply_to_id) and row.reply_to_user == row.user_id:\n",
    "            index_mapping[row.reply_to_id] = index_mapping[row[\"id\"]]\n",
    "    else:\n",
    "        couldnt_find += 1\n",
    "        threads_data.append([row])\n",
    "        index_mapping[row[\"id\"]] = len(threads_data) - 1\n",
    "        if not pd.isna(row.reply_to_id) and row.reply_to_user == row.user_id:\n",
    "            index_mapping[row.reply_to_id] = len(threads_data) - 1\n",
    "\n",
    "print(\"{} threads\".format(len(threads_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1591716010313,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "_G-FRfMRTgAz",
    "outputId": "77c42385-b53d-4245-f8b8-2534f7554ab8"
   },
   "outputs": [],
   "source": [
    "# What length do threads have?\n",
    "plt.figure()\n",
    "plt.hist([len(t) for t in threads_data if len(t) > 1], bins=np.arange(2, 30))\n",
    "plt.xlabel(\"Thread Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1582,
     "status": "ok",
     "timestamp": 1591716019238,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "a9PZnY2RNcX4",
    "outputId": "c841cc5d-8c15-4ca6-b680-d7a4a76a15c3"
   },
   "outputs": [],
   "source": [
    "# Find some example threads by screen name\n",
    "test_screen_name = \"AdamJKucharski\"\n",
    "\n",
    "for thread in threads_data:\n",
    "    if len(thread) > 1 and thread[0][\"screen_name\"] == test_screen_name:\n",
    "        for tweet in thread:\n",
    "            print(tweet.full_text)\n",
    "        print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74591,
     "status": "ok",
     "timestamp": 1591716178048,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "qlJVKWGuUk7t",
    "outputId": "f322f18c-96fc-47d7-f978-82602aa788f5"
   },
   "outputs": [],
   "source": [
    "# Write out all threads containing tweets that are in the original dataset \n",
    "\n",
    "must_include_ids = set(df[\"id\"].values)\n",
    "\n",
    "joined_data = []\n",
    "thread_id = 0\n",
    "for thread in threads_data:\n",
    "    if not any(t[\"id\"] in must_include_ids for t in thread):\n",
    "        continue\n",
    "    for t in thread:\n",
    "        td = t.to_dict()\n",
    "        td[\"thread_id\"] = thread_id\n",
    "        joined_data.append(td)\n",
    "    thread_id += 1\n",
    "    if thread_id % 100000 == 0:\n",
    "        print(thread_id)\n",
    "\n",
    "joined_df = pd.DataFrame(joined_data)\n",
    "joined_df.to_csv(os.path.join(output_dir, \"thread_annotated_tweets.csv\"),\n",
    "                 line_terminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1194,
     "status": "ok",
     "timestamp": 1591716209381,
     "user": {
      "displayName": "Venkatesh Sivaraman",
      "photoUrl": "",
      "userId": "08037131062068375405"
     },
     "user_tz": 240
    },
    "id": "qRIjSjjRWHr6",
    "outputId": "1bc77321-61d9-4780-8236-581098ce0b59"
   },
   "outputs": [],
   "source": [
    "# Sanity check: is every tweet in original data in joined data?\n",
    "joined_ids = set(joined_df[\"id\"].values)\n",
    "print(len(must_include_ids - joined_ids), \"tweets included in original but not new set\")\n",
    "print(len(joined_ids - must_include_ids), \"tweets included in new set but not original\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tweet_thread_augmentation.ipynb",
   "provenance": [
    {
     "file_id": "14YViT2hopL-40ogFE5YskZlzWbnvGO41",
     "timestamp": 1588452728320
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
